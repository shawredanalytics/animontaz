{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¬ Animontaz Video Generator (Colab Edition)\n",
    "Run this notebook to generate anime videos from images using a Cloud GPU (Google Colab T4).\n",
    "\n",
    "**Instructions:**\n",
    "1. Click **Runtime** -> **Change runtime type** -> Select **T4 GPU** (or better).\n",
    "2. Run the cells below in order.\n",
    "3. Click the public Gradio link (e.g., `https://...gradio.live`) to open the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install Dependencies (Wait for this to finish!)\n",
    "print(\"Installing libraries... This takes about 60 seconds.\")\n",
    "!pip install -q diffusers==0.30.0 transformers==4.44.2 accelerate opencv-python gradio>=5.0.0 safetensors einops pillow \"numpy<2.0.0\" imageio[ffmpeg] huggingface_hub\n",
    "print(\"Installation Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Animation Logic\n",
    "import torch\n",
    "from diffusers import AnimateDiffVideoToVideoPipeline, MotionAdapter, EulerAncestralDiscreteScheduler\n",
    "from diffusers.utils import export_to_video\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class AnimeAnimator:\n",
    "    def __init__(self):\n",
    "        print(\"Initializing AnimeAnimator...\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.dtype = torch.float16 if self.device == \"cuda\" else torch.float32\n",
    "        \n",
    "        print(f\"Device: {self.device}, Dtype: {self.dtype}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Load Motion Adapter\n",
    "            print(\"Loading Motion Adapter...\")\n",
    "            self.adapter = MotionAdapter.from_pretrained(\n",
    "                \"guoyww/animatediff-motion-adapter-v1-5-2\", \n",
    "                torch_dtype=self.dtype\n",
    "            )\n",
    "            \n",
    "            # 2. Load Pipeline (DreamShaper)\n",
    "            print(\"Loading AnimateDiff Video Pipeline (DreamShaper)...\")\n",
    "            self.pipe = AnimateDiffVideoToVideoPipeline.from_pretrained(\n",
    "                \"Lykon/DreamShaper\",\n",
    "                motion_adapter=self.adapter,\n",
    "                torch_dtype=self.dtype\n",
    "            )\n",
    "            \n",
    "            # 3. Set Scheduler\n",
    "            self.pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(\n",
    "                self.pipe.scheduler.config, \n",
    "                timestep_spacing=\"trailing\",\n",
    "                beta_schedule=\"linear\"\n",
    "            )\n",
    "            \n",
    "            # 4. Optimizations\n",
    "            print(\"Enabling VRAM optimizations...\")\n",
    "            self.pipe.enable_vae_slicing()\n",
    "            if self.device == \"cuda\":\n",
    "                self.pipe.enable_model_cpu_offload()\n",
    "            \n",
    "            print(\"Model loaded successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing model: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def preprocess_image(self, image_path, width=512, height=512):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = image.resize((width, height), resample=Image.LANCZOS)\n",
    "        return image\n",
    "\n",
    "    def generate(self, image_path, prompt, num_frames=24, strength=0.8, guidance_scale=7.5, steps=25, progress_callback=None):\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "        init_image = self.preprocess_image(image_path)\n",
    "        video_input = [init_image] * num_frames\n",
    "        \n",
    "        positive_prompt = (\n",
    "            f\"{prompt}, masterpiece, best quality, highres, anime style, \"\n",
    "            \"subtle breathing, slight head movement, wind blowing hair, \"\n",
    "            \"cinematic lighting, detailed background\"\n",
    "        )\n",
    "        \n",
    "        negative_prompt = (\n",
    "            \"bad quality, worse quality, low resolution, static, motionless, \"\n",
    "            \"deformed, distorted, disfigured, bad anatomy, extra limbs, \"\n",
    "            \"watermark, text, error\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Generating {num_frames} frames with prompt: {prompt}\")\n",
    "        \n",
    "        generator = torch.Generator(device=\"cpu\").manual_seed(42)\n",
    "        \n",
    "        def callback_fn(step, timestep, latents):\n",
    "            if progress_callback:\n",
    "                progress_callback(step, steps)\n",
    "            return latents\n",
    "\n",
    "        output = self.pipe(\n",
    "            video=video_input,\n",
    "            prompt=positive_prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            strength=strength,\n",
    "            generator=generator\n",
    "        )\n",
    "        \n",
    "        frames = output.frames[0]\n",
    "        output_path = \"output.mp4\"\n",
    "        export_to_video(frames, output_path, fps=8)\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Launch UI\n",
    "import gradio as gr\n",
    "import sys\n",
    "\n",
    "# Global model instance\n",
    "animator = None\n",
    "\n",
    "def load_model():\n",
    "    global animator\n",
    "    if animator is None:\n",
    "        print(\"Loading AI Model (this may take a minute)...\")\n",
    "        animator = AnimeAnimator()\n",
    "    return animator\n",
    "\n",
    "def generate_video(image_path, prompt, progress=gr.Progress()):\n",
    "    if not image_path:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        model = load_model()\n",
    "        if not prompt:\n",
    "            prompt = \"1girl, cute, smiling, looking at viewer, solo, upper body\"\n",
    "            \n",
    "        # Colab GPU Settings (Better than local CPU)\n",
    "        num_frames = 24\n",
    "        steps = 25\n",
    "        \n",
    "        def progress_wrapper(step, total):\n",
    "            progress((step, total), desc=f\"Denoising step {step}/{total}\")\n",
    "            \n",
    "        output_video = model.generate(\n",
    "            image_path=image_path,\n",
    "            prompt=prompt,\n",
    "            num_frames=num_frames, \n",
    "            strength=0.8,\n",
    "            steps=steps,\n",
    "            progress_callback=progress_wrapper\n",
    "        )\n",
    "        return output_video\n",
    "    except Exception as e:\n",
    "        raise gr.Error(f\"Generation Failed: {str(e)}\")\n",
    "\n",
    "# UI Layout\n",
    "with gr.Blocks(title=\"Animontaz Video MVP\") as demo:\n",
    "    gr.Markdown(\"# ðŸŽ¬ Animontaz Video Generator (Colab/Cloud)\")\n",
    "    \n",
    "    if not torch.cuda.is_available():\n",
    "        gr.Warning(\"No GPU detected! Please change Runtime Type to GPU.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_image = gr.Image(label=\"Upload Anime Image\", type=\"filepath\", height=400)\n",
    "            prompt_input = gr.Textbox(label=\"Prompt\", placeholder=\"Describe the character...\", lines=2)\n",
    "            generate_btn = gr.Button(\"âœ¨ Generate Video\", variant=\"primary\", size=\"lg\")\n",
    "        \n",
    "        with gr.Column():\n",
    "            output_video = gr.Video(label=\"Generated Animation\", height=400, autoplay=True)\n",
    "            \n",
    "    generate_btn.click(generate_video, inputs=[input_image, prompt_input], outputs=[output_video], api_name=\"generate_video\")\n",
    "\n",
    "print(\"Starting Gradio... The link will appear below momentarily.\")\n",
    "print(\"If it doesn't appear, make sure you are running on a GPU instance.\")\n",
    "demo.launch(share=True, debug=True, allowed_paths=['.'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}